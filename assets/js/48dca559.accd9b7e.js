"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[2984],{28453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>c});var r=t(96540);const i={},s=r.createContext(i);function l(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),r.createElement(s.Provider,{value:n},e.children)}},51355:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>c,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"elements/balar/intro","title":"balar","description":"The balar library provides an interface between SST and GPGPU-Sim, a cycle-level simulator modeling contemporary graphics processing units (GPUs) running GPU computing workloads written in CUDA. It supports two execution modes: trace-driven and direct-execution.","source":"@site/../docs/elements/balar/intro.md","sourceDirName":"elements/balar","slug":"/elements/balar/intro","permalink":"/sst-docs/docs/elements/balar/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/sstsimulator/sst-docs/edit/master/docs/../docs/elements/balar/intro.md","tags":[],"version":"current","lastUpdatedBy":"grvosku","lastUpdatedAt":1747692370000,"frontMatter":{"title":"balar"},"sidebar":"elements","previous":{"title":"ariel","permalink":"/sst-docs/docs/elements/ariel/intro"},"next":{"title":"QuickStart","permalink":"/sst-docs/docs/elements/balar/QuickStart"}}');var i=t(74848),s=t(28453),l=t(99563);const c={title:"balar"},a=void 0,o={},d=[{value:"Required dependencies",id:"required-dependencies",level:3},{value:"Optional dependencies",id:"optional-dependencies",level:3}];function u(e){const n={a:"a",admonition:"admonition",br:"br",code:"code",em:"em",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.em,{children:"balar"})," library provides an interface between SST and ",(0,i.jsx)(n.a,{href:"https://github.com/accel-sim/gpgpu-sim_distribution",children:"GPGPU-Sim"}),", a cycle-level simulator modeling contemporary graphics processing units (GPUs) running GPU computing workloads written in CUDA. It supports two execution modes: trace-driven and direct-execution."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Trace-driven: balar is driven by a test CPU that consume ",(0,i.jsx)(n.strong,{children:"CUDA API traces"})," (not to be confused with ",(0,i.jsx)(n.strong,{children:"SASS traces"})," for Accel-Sim) and launch CUDA calls."]}),"\n",(0,i.jsxs)(n.li,{children:["Direct-execution: a CPU model execute a CUDA binary linked with custom ",(0,i.jsx)(n.code,{children:"libcudart"})," and dispatch CUDA API calls to balar and GPGPU-Sim."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.em,{children:"BalarTestCPU"})," component is a trace-based test CPU that is included inside balar folder (",(0,i.jsx)(n.code,{children:"./testcpu/"}),") to run simulations with CUDA API call traces and data collected from a real GPU. It works by consuming a trace file and associated CUDA memory copy data files. The ",(0,i.jsx)(n.code,{children:"cudaMemcpyH2D"})," data payload is collected for program correctness. The ",(0,i.jsx)(n.code,{children:"cudaMemcpyD2H"})," data is collected to validate computation."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.em,{children:"BalarMMIO"})," is responsible for relaying CUDA API requests from SST to GPGPU-Sim. Currently it supports running with CUDA traces without a real CPU model (with BalarTestCPU) or with a ",(0,i.jsx)(n.a,{href:"../vanadis/intro",children:"Vanadis"})," core running RISCV + CUDA binary with a custom CUDA runtime (",(0,i.jsx)(n.code,{children:"libcudart_vanadis"})," inside ",(0,i.jsx)(n.code,{children:"./tests/vanadisLLVMRISCV/"}),"). This mode has been tested with a subset of Rodinia 2.0 benchmark kernels in unittest."]}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.em,{children:"dmaEngine"})," component performs memory data transfers between SST cache memory space and simulator memory space. It is required as balar will read/write the CPU data (i.e. ",(0,i.jsx)(n.code,{children:"cudaMemcpy()"})," with vanadis) and place them into GPGPU-Sim's memory space for functional simulation. In addition, dmaEngine is also used to read CUDA dispatch packet and write return value for the custom CUDA runtime."]}),"\n",(0,i.jsx)(n.admonition,{title:"At a Glance",type:"note",children:(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Source code:"})," ",(0,i.jsx)(n.a,{href:"https://github.com/sstsimulator/sst-elements/tree/master/src/sst/elements/balar",children:"sst-elements/.../balar"})," \xa0",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"SST name:"})," ",(0,i.jsx)(n.code,{children:"balar"})," \xa0",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"Maturity Level:"})," Prototype (2) \xa0",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"Development Path:"})," Active \xa0",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"Last Released:"})," SST 15.0"]})}),"\n",(0,i.jsxs)(n.admonition,{type:"warning",children:[(0,i.jsx)(n.p,{children:"Support for trace-driven mode currently is limited as it was used as early stage validation for balar implementation. It has only been tested with a simple integer vector add example."}),(0,i.jsx)(n.p,{children:"We are working on providing a more robust version of this with the new NVBit release. Including better trace format and better computation validation."})]}),"\n",(0,i.jsx)(n.h3,{id:"required-dependencies",children:"Required dependencies"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"CUDA"})," Version 11.0+ is recommended"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"GPGPUSim"})," Use the ",(0,i.jsx)(n.em,{children:"dev"})," branch from ",(0,i.jsx)(n.a,{href:"https://github.com/accel-sim/gpgpu-sim_distribution",children:"accel-sim/gpgpu-sim_distribution"})]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"optional-dependencies",children:"Optional dependencies"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://github.com/llvm/llvm-project",children:(0,i.jsx)(n.strong,{children:"LLVM"})})," For compiling RISCV + CUDA binary, 18.x.x+ should work (specifically, builds after resolving ",(0,i.jsx)(n.a,{href:"https://github.com/llvm/llvm-project/issues/57544",children:"llvm/llvm-project#57544"})," should work)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://github.com/riscv-collab/riscv-gnu-toolchain",children:(0,i.jsx)(n.strong,{children:"RISCV GNU Toolchain"})})," For compiling RISCV + CUDA binary. Generally all recent distribution should work, we have only tested on tag ",(0,i.jsx)(n.code,{children:"2024.08.06-nightly"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://github.com/accel-sim/gpu-app-collection/tree/sst_support",children:(0,i.jsx)(n.strong,{children:"gpu-app-collection"})})," For running unittest with Rodinia 2.0 kernels"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://github.com/accel-sim/Dockerfile/pkgs/container/accel-sim-framework/355611743?tag=SST-Integration-Ubuntu-22.04-cuda-11.7-llvm-18.1.8-riscv-gnu-2024.08.06-nightly",children:(0,i.jsx)(n.strong,{children:"Test Docker image"})})," You can also opt in the prebuilt docker image with all dependencies installed ",(0,i.jsx)(n.strong,{children:"except for GPGPU-Sim"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"OS: Ubuntu 22.04"}),"\n",(0,i.jsx)(n.li,{children:"CUDA: 11.7"}),"\n",(0,i.jsx)(n.li,{children:"LLVM: 18.1.8"}),"\n",(0,i.jsx)(n.li,{children:"RISCV: 2024.08.06-nightly"}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Pull prebuilt image\ndocker pull ghcr.io/accel-sim/accel-sim-framework:SST-Integration-Ubuntu-22.04-cuda-11.7-llvm-18.1.8-riscv-gnu-2024.08.06-nightly\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n","\n",(0,i.jsx)(l.A,{})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},81430:(e,n,t)=>{t.d(n,{W:()=>o});var r=t(96540),i=t(40797);const s=["zero","one","two","few","many","other"];function l(e){return s.filter((n=>e.includes(n)))}const c={locale:"en",pluralForms:l(["one","other"]),select:e=>1===e?"one":"other"};function a(){const{i18n:{currentLocale:e}}=(0,i.A)();return(0,r.useMemo)((()=>{try{return function(e){const n=new Intl.PluralRules(e);return{locale:e,pluralForms:l(n.resolvedOptions().pluralCategories),select:e=>n.select(e)}}(e)}catch(n){return console.error(`Failed to use Intl.PluralRules for locale "${e}".\nDocusaurus will fallback to the default (English) implementation.\nError: ${n.message}\n`),c}}),[e])}function o(){const e=a();return{selectMessage:(n,t)=>function(e,n,t){const r=e.split("|");if(1===r.length)return r[0];r.length>t.pluralForms.length&&console.error(`For locale=${t.locale}, a maximum of ${t.pluralForms.length} plural forms are expected (${t.pluralForms.join(",")}), but the message contains ${r.length}: ${e}`);const i=t.select(n),s=t.pluralForms.indexOf(i);return r[Math.min(s,r.length-1)]}(t,n,e)}}},99563:(e,n,t)=>{t.d(n,{A:()=>f});t(96540);var r=t(18215),i=t(93751),s=t(56289),l=t(81430),c=t(22887),a=t(50539),o=t(9303);const d={cardContainer:"cardContainer_fWXF",cardTitle:"cardTitle_rnsV",cardDescription:"cardDescription_PWke"};var u=t(74848);function h(e){let{href:n,children:t}=e;return(0,u.jsx)(s.A,{href:n,className:(0,r.A)("card padding--lg",d.cardContainer),children:t})}function m(e){let{href:n,icon:t,title:i,description:s}=e;return(0,u.jsxs)(h,{href:n,children:[(0,u.jsxs)(o.A,{as:"h2",className:(0,r.A)("text--truncate",d.cardTitle),title:i,children:[t," ",i]}),s&&(0,u.jsx)("p",{className:(0,r.A)("text--truncate",d.cardDescription),title:s,children:s})]})}function p(e){let{item:n}=e;const t=(0,i.Nr)(n),r=function(){const{selectMessage:e}=(0,l.W)();return n=>e(n,(0,a.T)({message:"1 item|{count} items",id:"theme.docs.DocCard.categoryDescription.plurals",description:"The default description for a category card in the generated index about how many items this category includes"},{count:n}))}();return t?(0,u.jsx)(m,{href:t,icon:"\ud83d\uddc3\ufe0f",title:n.label,description:n.description??r(n.items.length)}):null}function x(e){let{item:n}=e;const t=(0,c.A)(n.href)?"\ud83d\udcc4\ufe0f":"\ud83d\udd17",r=(0,i.cC)(n.docId??void 0);return(0,u.jsx)(m,{href:n.href,icon:t,title:n.label,description:n.description??r?.description})}function g(e){let{item:n}=e;switch(n.type){case"link":return(0,u.jsx)(x,{item:n});case"category":return(0,u.jsx)(p,{item:n});default:throw new Error(`unknown item type ${JSON.stringify(n)}`)}}function j(e){let{className:n}=e;const t=(0,i.$S)();return(0,u.jsx)(f,{items:t.items,className:n})}function f(e){const{items:n,className:t}=e;if(!n)return(0,u.jsx)(j,{...e});const s=(0,i.d1)(n);return(0,u.jsx)("section",{className:(0,r.A)("row",t),children:s.map(((e,n)=>(0,u.jsx)("article",{className:"col col--6 margin-bottom--lg",children:(0,u.jsx)(g,{item:e})},n)))})}}}]);